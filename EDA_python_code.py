# -*- coding: utf-8 -*-
"""Updated_RealEstate_EDA_Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RacSHy5xZ4oBKo7HVjANb-035T-YmymK

# Exploratory Data Analysis on S.S. Lootah Real Estate Data

**The purpose** of this project is to conduct exploratory data analysis on the provided datasets; summarize revenue, occupancy, and expired contracts per building, plus basic data cleaning and structure checks prior to any modeling.

**The goal** is to clean datasets and create visualizations.

**Part 1**: Imports, links, and loading  

**Part 2**: Data Exploration
- Data Cleaning
- Feature Engineering

**Part 3**: Building Visualizations  
   - Distributions Revenue (2021-2025)
   - Revenue vs. Previous Rent Per Property/Building
   - Occupancy Rate Per Building
   - Expired Contracts Per Building

**Part 4**: Evaluate and share results

**Task 1. Import, links, and loading**
"""

# Imports
import pandas as pd
import numpy as np
import datetime as dt
import matplotlib.pyplot as plt
import seaborn as sns

# Total Contracts dataset
df = pd.read_csv('/content/Total Contracts-Table 1.csv')

"""
**Task 2. Data Exploration and cleaning**"""

df.head(2)

df.shape

df.info()

# Duplicate rows
print(f"Number of duplicate rows in 'df': {df.duplicated().sum()}")

# Amount to numeric datatype
df["Amount"] = (
    df["Amount"]
    .astype(str)
    .str.replace(r"[^\d\.-]", "", regex=True)   # keep digits, . and -
)
df["Amount"] = pd.to_numeric(df["Amount"], errors="coerce")
missing_after = df["Amount"].isna().sum()
print(f"Missing values after conversion: {missing_after}")
print("Data type:", df["Amount"].dtype)
print("Total amount:", df["Amount"].sum())

#Contract end date to datetype column
col = "Contract End Date"


s = (
    df[col]
    .astype(str)
    .str.strip()
    .str.replace(r"[-.]", "/", regex=True)
    .replace({"nan": np.nan, "": np.nan})
)


mask_yyyy = s.str.match(r"^\s*\d{1,2}/\d{1,2}/\d{4}\s*$")
mask_yy    = s.str.match(r"^\s*\d{1,2}/\d{1,2}/\d{2}\s*$")


dt = pd.Series(pd.NaT, index=s.index, dtype="datetime64[ns]")


dt.loc[mask_yyyy] = pd.to_datetime(s[mask_yyyy], format="%d/%m/%Y", errors="coerce")


dt.loc[mask_yy] = pd.to_datetime(s[mask_yy], format="%d/%m/%y", errors="coerce")


unparsed = s[~(mask_yyyy | mask_yy) & s.notna()]
if len(unparsed):
    print("⚠️ Unparsed date strings (inspect/clean manually):")
    print(unparsed.value_counts().to_string())


df["contract_end_date_std"] = dt.dt.strftime("%d/%m/%Y")


df["contract_end_date_dt"] = dt

print(df[["Contract End Date", "contract_end_date_std"]].head(12))
print("Nulls after parse:", df["contract_end_date_dt"].isna().sum())

# Contract Start Date to Datetime dtype
import re

col = "Contract Start Date"

s = (
    df[col]
    .astype(str)
    .str.strip()
    .str.replace(r"[-.]", "/", regex=True)
    .replace({"nan": np.nan, "": np.nan})
)


mask_yyyy = s.str.match(r"^\s*\d{1,2}/\d{1,2}/\d{4}\s*$")
mask_yy    = s.str.match(r"^\s*\d{1,2}/\d{1,2}/\d{2}\s*$")


dt = pd.Series(pd.NaT, index=s.index, dtype="datetime64[ns]")


dt.loc[mask_yyyy] = pd.to_datetime(s[mask_yyyy], format="%d/%m/%Y", errors="coerce")


dt.loc[mask_yy] = pd.to_datetime(s[mask_yy], format="%d/%m/%y", errors="coerce")


unparsed = s[~(mask_yyyy | mask_yy) & s.notna()]
if len(unparsed):
    print("⚠️ Unparsed date strings (inspect/clean manually):")
    print(unparsed.value_counts().to_string())


df["contract_start_date_std"] = dt.dt.strftime("%d/%m/%Y")


df["contract_start_date_dt"] = dt


print(df[["Contract Start Date", "contract_start_date_std"]].head(12))
print("Nulls after parse:", df["contract_start_date_dt"].isna().sum())

# New 'month' and 'year' columns for Transaction Date
df["Transaction Date"] = pd.to_datetime(df["Period"], format="%b-%y", errors="coerce")
df["month_name"] = df["Transaction Date"].dt.strftime("%B")   # 'May', 'January', etc.
df["year"] = df["Transaction Date"].dt.year
df["month_num"] = df["Transaction Date"].dt.month
print(df[["Transaction Date", "month_name", "month_num", "year"]])

# Dropping incorrect columns and 'Unnamed: 25' column
df.drop(['Contract_Start_dt', 'contract_start_year', 'contract_start_month', 'contract_start_month_name', 'Unnamed: 25'], axis=1, inplace=True)

df.drop(['Transaction date', 'Contract Start Date', 'Contract End Date'], axis=1, inplace=True)

# Adding contract start and end year
df['contract_start_year'] = df['contract_start_date_dt'].dt.year
df['contract_end_year'] = df['contract_end_date_dt'].dt.year

# Creating contract duration column
df["contract_length_year"] = (df["contract_end_year"] - df["contract_start_year"])

df.rename(columns={'month_name': 'transaction_month_name', 'year': 'transaction_year', 'month_num':'transaction_month_num'}, inplace=True)

df.info()

# Total revenue per year
df.groupby('transaction_year')['Amount'].sum()

# Average revenue 2025
df[df['transaction_year'] == 2025].groupby('transaction_year')['Amount'].mean()

# Average revenue 2024
df[df['transaction_year'] == 2024].groupby('transaction_year')['Amount'].mean()

Month_order = ['January', 'February', 'March', 'April','May','June','July', 'August', 'September', 'October', 'November', 'December']

# Total revenue by month in 2024
df_by_month_2024 = df[df['transaction_year'] == 2024].groupby('transaction_month_name')['Amount'].sum()
df_by_month_2024 = df_by_month_2024.reindex(index=Month_order)
df_by_month_2024

df_by_month_2024.index

# Total revenue by month in 2025
df_by_month_2025 = df[df['transaction_year'] == 2025].groupby('transaction_month_name')['Amount'].sum()
df_by_month_2025 = df_by_month_2025.reindex(index=Month_order)
df_by_month_2025

df.describe()

df['Type'].describe()

df['Property Name.'].describe()

df['Contract Status'].describe()

df['Location'].describe()

df['Approve Status'].describe()

df['transaction_month_name'].describe()

"""**Initial Inspection**
* The total contracts dataset has 3199 rows and 26 columns. The span of contracts ranges from 2022 to 2029, and the average duration of contracts is 1 year.
* There are no duplicate rows in the dataset, so you can assume there are no duplicates. Hence, there is at most one row per internal ID for the contracts datasets and one row per building for the units dataset.
* The key variables (Amount, Contract Start Date, Contract End Date, Transaction Date) have zero missing values. However, there are several other variables with missing values; however, these missing values can't be replaced since we are dealing with personal information unique to each client/contract.
* The total revenue in 2024 was one hundred and fifty-seven million, whereas the total revenue in 2025 was fifty-one million. However, the data for 2025 only includes months from January to May.

### Data Visualization (Total Contracts Dataset)

Total revenue by month (2021-2025)
"""

revenue_by_month = df.groupby('transaction_month_name')['Amount'].sum()
revenue_by_month

plt.figure(figsize=(12,7))
ax = sns.barplot(x=revenue_by_month.index, y=revenue_by_month)
ax.set_xticklabels(Month_order)
plt.title('Total revenue by month (2021-2025)', fontsize=16);

"""The monthly revenues fluctuate month to month, with notable dips in the summer months of May, June, and July, and also in February.

Transactions by month
"""

plt.figure(figsize=(12,7))
df['transaction_month_name'] = pd.Categorical(df['transaction_month_name'], categories=Month_order, ordered=True)
sns.histplot(df['transaction_month_name'])
plt.title('Transactions by month', fontsize=10);
plt.show()

"""The number of transactions per month is fairly consistent from January to April, with a peak in May followed by a notable dip from June to December.

Total revenue by month (2024)
"""

plt.figure(figsize=(12,7))
ax = sns.barplot(x=df_by_month_2024.index, y=df_by_month_2024)
ax.set_xticklabels(Month_order)
plt.title('Total revenue by month 2024', fontsize=16);

"""February had the highest gross revenue of all months, and January had the least.

Total revenue by month (2025)
"""

plt.figure(figsize=(12,7))
ax = sns.barplot(x=df_by_month_2025.index, y=df_by_month_2025)
ax.set_xticklabels(Month_order)
plt.title('Total revenue by month 2025', fontsize=16);

"""May has so far had the highest gross revenue of all months, and January has had the least.

Contract duration
"""

plt.figure(figsize=(8,5))
sns.histplot(df['contract_length_year'], bins=range(1,10,1))
plt.title('Contract Duration');

"""Nearly all of the contracts are valid for a year, with some outliers such as 5 years.

Type of contracts
"""

# A Histogram of Type column
plt.figure(figsize=(10,5))
sns.histplot(df['Type'], bins=range(0,26,1))
plt.title('Type of Contracts');

"""Family contract types are the most common contracts, and SH-family are the least common type of contracts.

Location of Properties
"""

plt.figure(figsize=(14,5))
sns.histplot(df['Location'], bins=range(0,26,1))
plt.title('Location');

"""SSL - Dubai has the highest number of contracts, and SSL - Ajman has the lowest number of contracts.

Contract status
"""

plt.figure(figsize=(14,5))
sns.histplot(df['Contract Status'], bins=range(0,26,1))
plt.title('Location');

"""A majority of the contracts are active, with a small proportion of renewed, expired, backlog, closed, under process, legal in, and reversed. Nearly all of the contracts are approved, with only a few pending approval or rejected."""

plt.figure(figsize=(14,5))
sns.histplot(df['Approve Status'], bins=range(0,26,1))
plt.title('Location');

"""Nearly all of the contracts are approved, with only a few pending approval or rejected.

Number of files attached
"""

plt.figure(figsize=(14,5))
sns.histplot(df['File Attached'], bins=range(0,26,1))
plt.title('Location');

"""Around 1350 contracts have no files attached.

Payment receipt status
"""

plt.figure(figsize=(14,5))
sns.histplot(df['Payment Receipt'], bins=range(0,26,1))
plt.title('Location');

"""Approximately 2800 contracts have available payment receipts, with only 500 having no available payment receipts.

Comission percent of contracts
"""

plt.figure(figsize=(14,5))
sns.histplot(df['Comission % '], bins=range(0,26,1))
plt.title('Location');

"""Around 2000 contracts have a 0% commission, with around 1000 with 3% commission.

#### Units Dataset
"""

df_1 = pd.read_csv('/content/Unit Master-Table 1.csv')
df_1.head(10)

df_1.shape

# Check Duplicate rows
print(f"Number of duplicate rows in 'df_1': {df_1.duplicated().sum()}")

df_1.info()

df_1["Price_clean"] = (
    df_1["Price"]
    .astype(str)
    .str.replace(r"[^\d\.\-]", "", regex=True)
    .replace("", pd.NA))


df_1["Price_clean"] = pd.to_numeric(df_1["Price_clean"], errors="coerce")


print(df_1[["Price", "Price_clean"]].head())
print("Total sum:", df_1["Price_clean"].sum())
print("Data type:", df_1["Price_clean"].dtype)

df_1['Price_clean'].describe()

df_1.drop(['Unnamed: 11'], axis=1, inplace=True)

df_1['Building Name'].describe()

df_1['Building Code'].describe()

df_1['Name'].describe()

df_1['Old Unit No'].describe()

df_1['Unit Type'].describe()

df_1['PREMISES NO'].describe()

df_1['Rental Status'].describe()

df_1['Property Service Type'].describe()

df_1['Building Segment'].describe()

df_1['Unit Segment'].describe()

df_1['Rental Status'].value_counts()

"""**Initial Observation:**
- There are 58 different properties in the dataset, with S.S. LOOTAH RESIDENCE JVC having the most units in the dataset.
- There are 2375 leased units, 657 vacant units, 58 booked, and 1 expired with zero missing values.
- The average price of a unit is sixty thousand, two hundred and forty-two.

**Task 4. Feature Engineering**
"""

#Occupancy Rate based on Rental Status

occupancy_map = {
    "LEASED": 1,
    "BOOKED": 1,
    "VACANT": 0,
    "EXPIRED": 0
}

df_1["occupancy_flag"] = df_1["Rental Status"].str.upper().map(occupancy_map)

print(df_1[["Rental Status", "occupancy_flag"]].head())
print("\nOccupancy rate (%):", df_1["occupancy_flag"].mean() * 100)

df_1.groupby("Building Name")["occupancy_flag"].mean().mul(100).round(2)

#Expired contracts as of today
df["contract_end_date_dt"] = pd.to_datetime(df["contract_end_date_dt"], errors="coerce")

today = pd.Timestamp.today().normalize()

df["is_expired"] = (df["contract_end_date_dt"] < today).astype(int)

print(df[["contract_end_date_dt", "is_expired"]].head(10))
print("\nTotal expired contracts:", df["is_expired"].sum())
print("Active contracts:", len(df) - df["is_expired"].sum())

expired_rate = (df["is_expired"].mean() * 100).round(2)
print(f"Expired contract rate: {expired_rate}%")

"""**Insights (Feature Engineering)**
- The total occupancy rate is 78.71%, which means there are approximately 2,433 occupied units out of 3091 units.
- There are 1977 expired contracts (61.8%) as of today, in comparison to 1222 active contracts, which makes over 50% of units with expired contracts--an unusually high expired count that needs further attention (it could be due to seasonality, policy changes, data lag).

**Task 6. Key Visualizations**

**Task 6.a. Revenue Distribution**

**The goal** is to understand central tendency, spread, and potential outliers.
"""

#Distribution of Amount(Revenue)
q1, q99 = df['Amount'].quantile([0.01, 0.99])
filtered = df[(df['Amount'] >= q1) & (df['Amount'] <= q99)]

plt.figure(figsize=(8, 3))
sns.boxplot(x=filtered['Amount'], fliersize=2, color='skyblue')
plt.title('Distribution of Amount (1st–99th percentile zoom)')
plt.xlabel('Amount (AED)')
plt.tight_layout()
plt.show()

revenue_by_type = df.groupby('Type')['Amount'].mean()
revenue_by_type

plt.figure(figsize=(12,7))
ax = sns.barplot(x=revenue_by_type.index, y=revenue_by_type)
plt.title('Total revenue by Type (2021-2025)', fontsize=16);

"""**Insights (Revenue Distribution):**  
- The revenue distribution is right-skewed, with nearly all the revenue in the AED25k-57k range.
- The mean revenue amount varies based on the contract type. Although commercial contracts have the highest amount of revenue generated, the family contracts are the most frequent type of contract in our dataset. Further, it's expected that the sister company type will have the lowest revenue pool because sister company contracts were the second least plentiful in the dataset.

**Task 6.b. Revenue 2025 vs. Revenue 2024 (Per Property)**

**The goal** is to compare current revenue against previous rent to quantify growth/decline.
"""

building_revenue = (
    df.groupby(["Oc", "transaction_year"], as_index=False)["Amount"]
      .sum()
)

building_revenue = building_revenue[building_revenue["transaction_year"].isin([2024, 2025])]

order = (
    building_revenue.groupby("Property Name.")["Amount"]
    .sum()
    .sort_values(ascending=False)
    .index
)

plt.figure(figsize=(12, 6))
sns.barplot(
    data=building_revenue,
    x="Property Name.",
    y="Amount",
    hue="transaction_year",
    order=order,
    palette="coolwarm"
)

plt.title("Revenue Comparison per Building (2024 vs 2025)", fontsize=14, weight="bold")
plt.xlabel("Building Name", fontsize=12)
plt.ylabel("Total Revenue (AED)", fontsize=12)
plt.xticks(rotation=45, ha="right")
plt.legend(title="Year")
plt.tight_layout()
plt.show()

"""**Insights (Revenue vs Previous):**  
- The top three properties by revenue in 2024 are Al Jawhara Garden Hotel, Al Barsha BLDG, and Al Mamzer Tower. Whereas, the top three in 2025 as of May 2025 are Al Jawhara residential building, Al Qouz Lab Camp, and Al Mamzar tower.
- It will be beneficial to investigate drivers such as renovations, unit mix changes, and concessions for notable variances.

**Task 6.c. Occupancy Rate per Building**

**The goal** is to rank buildings by occupancy to identify underperformers and capacity pockets.
"""

building_occupancy = (
    df_1.groupby("Building Name")["occupancy_flag"]
        .mean()
        .mul(100)
        .round(2)
        .sort_values(ascending=False)
        .head(20)
)

plt.figure(figsize=(10, 6))
sns.barplot(
    x=building_occupancy.values,
    y=building_occupancy.index,
    palette="viridis"
)

plt.title("Top 20 Buildings by Occupancy Rate", fontsize=16, weight="bold")
plt.xlabel("Occupancy Rate (%)", fontsize=12)
plt.ylabel("Building Name", fontsize=12)
plt.xlim(0, 105)
plt.tight_layout()


plt.show()

"""**Insights (Occupancy):**  
- All of these top 20 buildings have a 100% occupancy rate based on their rental status in the dataset. I recommend checking seasonality or recent handovers influencing occupancy baselines.

**Task 6.d. Expired Contracts per Building**

**The goal** is to quantify contract expiries to prioritize renewals or new leasing activities.
"""

latest_expired_contracts = df.groupby('Property Name.').agg({'is_expired': 'sum'})
latest_expired_contracts

expired_per_building = (
    df.groupby("Property Name.")["is_expired"]
      .sum()
      .sort_values(ascending=False)
      .head(20)
)

plt.figure(figsize=(12, 7))
ax = sns.barplot(
    x=expired_per_building.index,
    y=expired_per_building.values,
    palette="Reds_r"
)
plt.title("Top 20 Buildings by Expired Contracts", fontsize=16, weight="bold")
plt.xlabel("Propery Nanme.", fontsize=12)
plt.ylabel("Number of Expired Contracts", fontsize=12)
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

"""**Insights (Expired Contracts):**  
- The 3 buildings with the highest number of expired leases as of today are Al Mamzer Tower (245), Al Nahda 4 BLDG (110), and Al Barsha BLDG (106). These buildings may need proactive renewal campaigns and a deeper analysis of occupancy trends to balance vacancy risk.

**Task 8. Conclusion**

1. Revenue distribution shows (e.g., Al Jawhara Garden Hotel, Al Barsha BLDG, and Al Mamzer Tower, Al Jawhara residential building, and Al Qouz Lab Camp) concentration in a few buildings; candidates for pricing review and yield management.  
2. Several buildings have zero occupancy; recommend targeted marketing and agent incentives.  
3. For expired leases cluster in buildings with a high number of expired leases; prioritize renewal outreach to reduce churn.
"""

df.to_csv("Cleaned_Totalcontracts_Data.csv", index=False)

df_1.to_csv("Cleaned_units_data.csv", header=True)

print("Datasets successfully saved as CSV files!")

df_3 = pd.read_csv('/content/Cleaned_units_data.csv')
df_3.head(10)



